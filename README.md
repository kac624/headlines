# headlines

### News headline classification using Pretrained LLMs

This project aims to classify news articles into categories based on the subject-matter of the article. The primary model under consideration is the Bidirectional Encoder Representations from Transformers (BERT) model. The developer data consists of over 200,000 headlines for news articles, along with short descriptions of each article. The articles are all with HuffPost, published between 2012 and 2022. The target label is the news category (e.g. Business, Sports, Politics). The data was sourced from Kaggle.com [1].

Below is a description of the various scripts (all saved under the `scripts` folder). Configuration is handled via the `_config.json` and `_hp_grid.json` files. The `overview.ipynb` provides an end-to-end view of the development procedure, covering exploratory data analysis, benchmark and baseline training, tuning for performance, and final evaluation.

APRIL 2024 UPDATE: I've adjusted the code to allow for usage of other pre-trained with the `PRETRAINED_LM` parameter. Models compared for performance include:  
-`bert-base-uncased`  
-`roberta-base`  
-`meta-llama/meta-llama-3-8b`  
-TBD  

### preprocess.py

This script loads in the dataset from Kaggle, splits it into training, validation and testing subsets, then processes text sequences for consumption by models. Specifically, the script generates vectorized representations of text sequences using (i) the Term Frequency-Inverse Document Frequency (TF-IDF) approach, primarily for use in the benchmark models; and (ii) tokenized sequences using the `AutoTokenizer` from `transformers`. Labels are integer encoded, and a dictionary is saved (`code_labels_dict.json`) to aid in conversion between integer and natural language labels. All data is saved in `.pt` format under the `data` folder. The `_config.json` file allows for configuration of the training / test split ratio, the max length used by `AutoTokenizer`, the consolidation of classes, and toggling of data augmentation.

Note that this script uses the Kaggle API for Python, and requires that `kaggle.json` be saved to your PATH for authentication. See instructions here: https://python.plainenglish.io/how-to-use-the-kaggle-api-in-python-4d4c812c39c7.

### train_benchmarks.py

This script trains two benchmark models: logistic regression and XGBoost, both of which use TF-IDF as input (saved as `tfidf_train.pt` under `data`). High-level performance metrics are printed to screen and both models are saved under `models`.

### train_llm.py

This scripts trains the `AutoModelForSequenceClassification` model using the processed input IDs and attention masks generated by `AutoTokenizer` during preprocessing (saved as `train_input_ids.pt` and `train_att_masks.pt` under `data`). The `_config.json` file allows for configuration of the number of epochs, the batch size, the learning rate, the dropout rate (for regularization), the balance factor (which determines the degree to which minority classes are upsampled), and the patience factor (which determines the number of epochs the model will be trained with no improvement in validation error before early stopping kicks in). The best-fit model (i.e. that with the lowest validation error) will be saved in `models`. If `LOGGING` is enabled in the config, a detailed log file will be saved in `logs`.

### tuning.py

This script iterates through various configurations of (hyper)parameters and logs the models' resulting performance for comparison. the grid of hyperparameter values is determined by `_hp_grid.json`. Users can also set two parameters within the script â€” `PREPROCESS_FOR_TUNING` (which determines whether the `preprocess.py` script is run before model fitting) and `PREPROCESS_ONLY_ONCE` (whjich determines whether the `preprocess.py` script is run before only the *first* fitting or before *every* fitting). Results are saved under `logs`.

### utils.py

Contains several functions used in the `preprocess.py` script. It also contains a dictionary of consolidated classes (news categories) that will determine how classes are consolidated (if `CONSOLIDATE_LABELS` if `True`).

### Sources

[1] Misra, Rishabh. "News Category Dataset." arXiv preprint arXiv:2209.11429 (2022). Sourced from https://www.kaggle.com/datasets/rmisra/news-category-dataset.